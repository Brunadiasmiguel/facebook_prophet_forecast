{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf807ad-8ecd-4d11-b4d8-8e4340299940",
   "metadata": {},
   "source": [
    "# Forecasting with Prophet in Python on BQ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4d563-c857-4381-bb09-291ab0465823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07dcce-4866-4d16-8ece-a8b195a0b5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install google-auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e88cb9-778a-4fc4-82e5-12d45206277c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163af7d-88ed-41f3-b6bb-b81d12877871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f7ae7-ae22-4b38-aed0-0cfb6d4da35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c25f2c-c6a5-44f8-9e7d-6ce9ab844221",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd405f56-73ad-4dc6-bf97-a76ae395d336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.diagnostics import cross_validation\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "\n",
    "from scipy import stats as st\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import logging\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec97a3b-c39d-49a0-901e-0bc9557c9064",
   "metadata": {},
   "source": [
    "## 2. Access dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498acd3-0632-47cf-9ff0-9f98ee779d37",
   "metadata": {},
   "source": [
    "### 2.1 Example how to access BQ data from a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee289064-ed90-40ca-a4d9-bc745e283d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bigquery credentials to google cloud\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"YOUR JSON CREDENTIALS\"\n",
    "\n",
    "# bigquery\n",
    "\n",
    "credentials, your_project_id = google.auth.default(\n",
    "scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "\n",
    "# create clients\n",
    "\n",
    "bqclient = bigquery.Client(credentials=credentials, project=your_project_id,)\n",
    "bqstorageclient = bigquery_storage.BigQueryReadClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1df010-3433-419b-b901-d93fb5dae431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the bigquery table and create dataframe\n",
    "\n",
    "string = \"\"\"\n",
    "select *\n",
    "FROM dummy_table\n",
    "\"\"\"\n",
    "\n",
    "df = (\n",
    "    bqclient.query(string)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=bqstorageclient)\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641b7ea-1ad3-4d54-bb26-7a75e8116a84",
   "metadata": {},
   "source": [
    "### 2.2 Example accessing CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bedd1-9355-4ccc-a94a-66c54eb33af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb=pd.read_csv(\"CSV_name.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0ceac-a4da-4e32-af18-b96a1309411c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 Example creating fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4170937-cf90-4a24-9cd0-8b6788204584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be using this one as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86baaa35-c294-44b6-8e65-b07ab8b64363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to generate fake data\n",
    "\n",
    "def generate_fake_data():\n",
    "    start_date = datetime(2022, 1, 1)\n",
    "    end_date = datetime(2023, 12, 31)\n",
    "    current_date = start_date\n",
    "\n",
    "    data = {'Date': [], 'Downloads': [], 'Country': []}\n",
    "    downloads_base = 1000  \n",
    "\n",
    "    while current_date <= end_date:\n",
    "        \n",
    "        # add seasonality and trend components\n",
    "        \n",
    "        seasonality = 100 * (1 + 0.5 * (1 + (current_date.month % 12) / 12))\n",
    "        trend = 10 * (current_date.year - 2022)\n",
    "\n",
    "        # generate random noise\n",
    "        \n",
    "        noise = random.uniform(-50, 50)\n",
    "\n",
    "        # calculate total downloads\n",
    "        \n",
    "        downloads = int(downloads_base + seasonality + trend + noise)\n",
    "\n",
    "        # append data to the dictionary\n",
    "        \n",
    "        data['Date'].append(current_date)\n",
    "        data['Downloads'].append(downloads)\n",
    "        data['Country'].append('US')\n",
    "\n",
    "        # move to the next day\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d004e-bc88-47a3-9c15-7703a456245f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the data\n",
    "\n",
    "fake_data = generate_fake_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4390a-278a-441f-abf0-0969ff89fff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create df\n",
    "\n",
    "df_fb = pd.DataFrame(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fcca34-e88b-4024-b8bc-5b1a49b9f91c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confirm\n",
    "\n",
    "df_fb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09599a8-e453-4754-a20c-fd07d0713fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Using Prophet for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29186727-b4ef-4c51-b0fc-62fab8209d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code can be used for other applications besides 4.\n",
    "# No real data is used, so it is all hypothetical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c3d97-3d69-427b-ab8e-475bcce14d7b",
   "metadata": {},
   "source": [
    "### 3.1 Defining placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a88f61-de73-46e9-a94e-43cadbdc9143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining placeholders and limited to two weeks in the context of the application in 4. and the data itself\n",
    "\n",
    "country=[\"US\"]\n",
    "start_date=\"2023-12-05\"\n",
    "update_date=\"2023-12-18\"\n",
    "end_date=\"2023-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c174f-34f0-4793-a6c9-54b4be754998",
   "metadata": {},
   "source": [
    "### 3.2 Define all data dataset and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d96fc-7f18-4d5b-ad78-db49ad1aee26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the function that returns all data dataset and train dataset\n",
    "# Function line 1: select country\n",
    "# Function line 2: select the two variables for Prophet, time and dimension to forecast\n",
    "# Function line 3: create columns designed for Prophet, \"ds\" for date, \"y\" for the dimension to forecast (following documentation)\n",
    "# Function line 4: make sure only positive numbers are available\n",
    "# Funtion line 5: convert \"ds\" to date time as needed to apply Prophet\n",
    "# Function line 6: define the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d7abc-9962-4390-9cd5-f9b99ad1579c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_global_df (country):\n",
    "    df=df_fb[(df_fb[\"Country\"]==country)]\n",
    "    df=df[[\"Date\",\"Downloads\"]]\n",
    "    df.columns=[\"ds\",\"y\"]\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df=df[df[\"y\"]>0]\n",
    "    df['ds']=pd.to_datetime(df['ds'])\n",
    "    df_train=df[(df[\"ds\"]<update_date)]\n",
    "    return df, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7364c-2443-4836-8ad5-0187cd3d1865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call train set as example\n",
    "\n",
    "train_global_df(\"US\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05042d-6837-432b-bde8-06ddb4a3a0be",
   "metadata": {},
   "source": [
    "### 3.3 Define the Prophet method, create the forecast and an accuracy evaluation (MAPE: Mean Absolute Percentage Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95da598-2568-4023-a507-bd4bd54722ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the function that returns the forecast and the MAPE\n",
    "# Function line 1: define Prophet call and its hyperparameter tuning\n",
    "# Function line 2: add country holidays\n",
    "# Function line 3: fit the train set\n",
    "# Function line 4: set the forecast length to 30 days (option to decrease runing time)\n",
    "# Funtion line 5: create future dataframe based on previous information\n",
    "# Function line 6: apply the forecast\n",
    "# Function line 7 to 10: manipulate to compare forecast with actual numbers\n",
    "# Function line 11: define MAPE call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab9ad5-47df-4c86-b121-5273713293ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forecast (country):\n",
    "    fb=Prophet(changepoint_prior_scale=0.15, seasonality_prior_scale=0.1)\n",
    "    fb.add_country_holidays(country_name=country)\n",
    "    fb.fit(train_global_df(country)[1])\n",
    "    forecast_length=95\n",
    "    future=fb.make_future_dataframe (periods=forecast_length)\n",
    "    forecast=fb.predict(future)\n",
    "    forecast=forecast[['ds','yhat']]\n",
    "    plot=forecast.merge(train_global_df(country)[0],how=\"left\")\n",
    "    plot=plot[plot[\"ds\"]<end_date]\n",
    "    plot[\"diff_forecast-actuals\"]=plot[\"y\"]-plot[\"yhat\"]\n",
    "    mape=performance_metrics (cross_validation(fb, horizon = '30 days')).iloc[10,4]\n",
    "    return plot, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32d33a-27eb-4dc1-bff9-fb6135d0429a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check forecast\n",
    "\n",
    "forecast(\"US\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0ae3f-7f9f-4eaa-9c0f-d2bd6aff0468",
   "metadata": {},
   "source": [
    "### 3.4 Define a static forecast and MAPE accuracy measure to avoid running the function multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdba19-762f-457a-a406-0c8360e75936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# forecast\n",
    "\n",
    "plot_total=forecast(\"US\")[0]\n",
    "plot_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75739ae0-8c0f-46c0-bb2b-b021ba752f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mape\n",
    "\n",
    "mape=forecast(\"US\")[1]\n",
    "mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420df381-1c78-476e-a320-d95e68f0cde6",
   "metadata": {},
   "source": [
    "### 3.5 Visualize the Forecast vs Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365ee5d-fe6f-4ac9-a4cc-56ee587b3618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the function that creates the graph\n",
    "# Line 1: Define the size\n",
    "# Line 2: Define the scatter plot for the forecasted cases\n",
    "# Line 3: Define the scatter plot for the true/ actual cases\n",
    "# Line 4: Create a vertical line with the update date/ until the date we defined the train dataset\n",
    "# Following lines: Define legend, lable and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af266ece-ec29-44a6-9e33-0e4f06fa32d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_viz_total ():\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(plot_total['ds'], plot_total['yhat'], label='Forecasted Cases')\n",
    "    plt.scatter(plot_total['ds'], plot_total['y'], label='True Cases')\n",
    "   # plt.axvline(x=update_date,color=\"red\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xlabel(\"Date\", size=10)\n",
    "    plt.ylabel(\"Downloads\", size=10)\n",
    "    plt.title(\"Forecast vs Actual Downloads US\", size=15)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed742151-6492-4bac-88d6-b72eeec8d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call the function\n",
    "\n",
    "data_viz_total ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae9651-b891-4d0a-9bef-a21bb1b5e693",
   "metadata": {},
   "source": [
    "## 4. Application Example: Daily Uplift from ASO Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377309c8-6452-4241-8848-2e19ac165ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal is to compare the forecast of downloads after an ASO optimization to measure impact\n",
    "# Impact would be measured by comparing the actuals and the forecast\n",
    "# The forecast in this context would represent the downloads expected without any update\n",
    "# The difference between actuals and forecast would represent the uplift (or not) from the update - was it successful or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0276348-567a-4c89-b91e-a153e94042ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix plot function \n",
    "\n",
    "plot=plot_total[(plot_total[\"ds\"]>=start_date) & (plot_total[\"ds\"]<=end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61367ca-ca34-4576-8c17-1c87ba9fe63b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funcion fb prophet\n",
    "\n",
    "def impact_measurement(country):\n",
    "    plot2weeks=plot[(plot[\"ds\"]>=update_date) & (plot[\"ds\"]<=end_date)]\n",
    "    forecast_table=pd.DataFrame(index=[0],columns=[\"Country\",\"Forecast\",\"Actuals\",\"Daily Uplift\",\"MAPE\"])\n",
    "    forecast_table[\"Country\"]=country\n",
    "    forecast_table[\"Forecast\"]=sum(plot2weeks[\"yhat\"])/len(plot2weeks[\"yhat\"])\n",
    "    forecast_table[\"Actuals\"]=sum(plot2weeks[\"y\"])/len((plot2weeks[\"y\"]))\n",
    "    forecast_table[\"Daily Uplift\"]=sum(plot2weeks['diff_forecast-actuals'])/len(plot2weeks['diff_forecast-actuals'])\n",
    "    forecast_table[\"MAPE\"]=mape\n",
    "    forecast_table=forecast_table.round(2)\n",
    "    return forecast_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc9550-9e09-4479-afd9-9843f34b5cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "impact_measurement (\"US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13941a1-6d9c-43ad-911c-2536aa4a45b8",
   "metadata": {},
   "source": [
    "## 5. Eliminate Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0fb0b-0b2f-49ff-bdc7-9fc3ed9d3fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a dataframe based on the train set\n",
    "\n",
    "df_outliers=train_global_df(\"US\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6085bb-d971-4fcf-b790-7cc62bbe34c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outliers function for search\n",
    "\n",
    "def outliers ():\n",
    "    df_outliers_stats=df_outliers.describe().transpose()\n",
    "    iqr_out=df_outliers_stats.loc[\"y\"][\"75%\"]-df_outliers_stats.loc[\"y\"][\"25%\"]\n",
    "    df_out=df_outliers[(df_outliers[\"y\"]>=(df_outliers_stats.loc[\"y\"][\"25%\"]-(1.5*iqr_out))) & (df_outliers[\"y\"]<=(df_outliers_stats.loc[\"y\"][\"75%\"]+(1.5*iqr_out)))]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2166246-66ab-4beb-8bd3-98048b03fc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call function\n",
    "\n",
    "outliers ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d641f7b-959e-4d8d-8971-958f9439bdc8",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53ced4-3db9-4055-83b0-cee2fd6315bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1,0.15, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0,5.0, 10.0],\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "\n",
    "for params in all_params:\n",
    "    fb = Prophet(**params).fit(train_global_df (\"US\")[1])  # Fit model with given params\n",
    "    df_cv = cross_validation(fb, horizon='30 days', parallel=\"processes\")\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496f97c-1c64-4b4d-b9ba-28dbcf79d293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the best ones\n",
    "\n",
    "best_params = all_params[np.argmin(rmses)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c69c90-4c01-4206-bd70-bd98d352ee2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
